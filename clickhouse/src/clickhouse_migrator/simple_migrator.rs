use clickhouse::Client;
use anyhow::{Result, Context};
use std::collections::{BTreeMap, HashSet};
use serde::{Deserialize, Serialize};
use std::time::Instant;

pub struct SimpleMigrator {
    client: Client,
    service_name: String,
    migrations_path: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MigrationRecord {
    pub version: String,
    pub name: String,
    pub applied_at: String,
    pub execution_time_ms: u64,
    pub checksum: String,
    pub success: bool,
    pub error_message: String,
}

#[derive(Debug, Clone)]
pub struct MigrationFile {
    pub version: String,
    pub name: String,
    pub up_sql: String,
    pub down_sql: Option<String>,
    pub checksum: String,
    pub is_baseline: bool,
}

#[derive(Debug)]
pub struct MigrationSummary {
    pub successful: Vec<MigrationRecord>,
    pub failed: Vec<FailedMigration>,
    pub total_time: std::time::Duration,
}

#[derive(Debug)]
pub struct FailedMigration {
    pub version: String,
    pub name: String,
    pub error: String,
}

impl SimpleMigrator {
    pub async fn new(database_url: &str, service_name: &str, migrations_path: &str) -> Result<Self> {
        let client = Client::default()
            .with_url(database_url)
            .with_database("default")
            .with_user("default")
            .with_password("ClickHouse@123");
        
        let migrator = Self {
            client,
            service_name: service_name.to_string(),
            migrations_path: migrations_path.to_string(),
        };
        
        // åªåˆ›å»ºä¸€ä¸ªè¿ç§»è®°å½•è¡¨
        migrator.setup_migrations_table().await?;
        
        Ok(migrator)
    }
    
    /// åˆ›å»ºè¿ç§»è®°å½•è¡¨ï¼ˆå”¯ä¸€çš„"meta"è¡¨ï¼‰
    async fn setup_migrations_table(&self) -> Result<()> {
        let table_name = format!("_migrations_{}", self.service_name);
        
        let create_sql = format!(
            r#"
            CREATE TABLE IF NOT EXISTS {table_name} (
                version String,
                name String,
                applied_at DateTime64(3) DEFAULT now64(3),
                execution_time_ms UInt64,
                checksum String,
                success UInt8,
                error_message String DEFAULT ''
            ) ENGINE = MergeTree()
            ORDER BY version
            "#
        );
        
        self.client.query(&create_sql).execute().await
            .context("Failed to create migrations table")?;
        
        Ok(())
    }
    
    /// ä¸»è¦å…¥å£ï¼šè¿è¡Œå¾…å¤„ç†çš„è¿ç§»
    pub async fn migrate(&self) -> Result<MigrationSummary> {
        println!("ğŸš€ Starting migration for service: {}", self.service_name);
        
        let start_time = Instant::now();
        
        // 1. æ‰«æè¿ç§»æ–‡ä»¶ï¼ˆåªæ‰«æä¸€æ¬¡ï¼‰
        let migration_files = self.scan_migration_files().await?;
        
        // 2. è·å–å·²æ‰§è¡Œçš„è¿ç§»
        let applied_versions = self.get_applied_versions_from_database().await?;
        
        // 3. ç­›é€‰å¾…æ‰§è¡Œçš„è¿ç§»ï¼ˆæŒ‰ç‰ˆæœ¬å·æ’åºï¼‰
        let mut pending: Vec<&MigrationFile> = migration_files
            .values()
            .filter(|m| !applied_versions.contains(&m.version))
            .collect();
        
        // æŒ‰ç‰ˆæœ¬å·æ’åº
        pending.sort_by(|a, b| a.version.cmp(&b.version));
        
        if pending.is_empty() {
            println!("âœ… æ²¡æœ‰å¾…å¤„ç†çš„è¿ç§»ï¼Œæ•°æ®åº“å·²æ˜¯æœ€æ–°çŠ¶æ€");
            return Ok(MigrationSummary::no_migrations());
        }
        
        println!("ğŸ“‹ å‘ç° {} ä¸ªå¾…å¤„ç†çš„è¿ç§»", pending.len());
        for migration in &pending {
            println!("  - {}: {}", migration.version, migration.name);
        }
        
        // 4. æ‰§è¡Œè¿ç§»
        let mut summary = MigrationSummary::new();
        
        for migration in pending {
            println!("ğŸ”§ Executing migration: {} - {}", migration.version, migration.name);
            
            let result = self.execute_migration(migration).await;
            
            match result {
                Ok(record) => {
                    summary.successful.push(record);
                    println!("âœ… Migration {} completed", migration.version);
                }
                Err(e) => {
                    println!("âŒ Migration {} failed: {}", migration.version, e);
                    summary.failed.push(FailedMigration {
                        version: migration.version.clone(),
                        name: migration.name.clone(),
                        error: e.to_string(),
                    });
                    
                    // é»˜è®¤ç­–ç•¥ï¼šé‡åˆ°å¤±è´¥å°±åœæ­¢
                    if !self.should_continue_on_failure() {
                        break;
                    }
                }
            }
        }
        
        summary.total_time = start_time.elapsed();
        Ok(summary)
    }
    
    /// æ‰«æè¿ç§»æ–‡ä»¶ç›®å½•
    async fn scan_migration_files(&self) -> Result<BTreeMap<String, MigrationFile>> {
        use tokio::fs;
        use std::path::Path;
        
        let migrations_dir = Path::new(&self.migrations_path);
        if !migrations_dir.exists() {
            println!("âš ï¸  è¿ç§»ç›®å½•ä¸å­˜åœ¨: {}", self.migrations_path);
            return Ok(BTreeMap::new());
        }
        
        let mut migration_files = BTreeMap::new();
        let mut entries = fs::read_dir(migrations_dir).await?;
        
        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();
            
            if path.extension() == Some(std::ffi::OsStr::new("sql")) {
                match self.parse_migration_file(&path).await {
                    Ok(migration) => {
                        println!("ğŸ“ å‘ç°è¿ç§»æ–‡ä»¶: {} - {}", migration.version, migration.name);
                        migration_files.insert(migration.version.clone(), migration);
                    }
                    Err(e) => {
                        println!("âš ï¸  Failed to parse migration file {:?}: {}", path, e);
                    }
                }
            }
        }
        
        println!("ğŸ“‹ æ€»å…±æ‰«æåˆ° {} ä¸ªè¿ç§»æ–‡ä»¶", migration_files.len());
        Ok(migration_files)
    }
    
    /// è§£æå•ä¸ªè¿ç§»æ–‡ä»¶
    async fn parse_migration_file(&self, file_path: &std::path::Path) -> Result<MigrationFile> {
        use regex::Regex;
        
        let content = tokio::fs::read_to_string(file_path).await?;
        
        // è§£ææ–‡ä»¶åï¼šV000__baseline_existing_database.sql æˆ– V001__create_users_table.sql
        let filename = file_path.file_stem()
            .and_then(|s| s.to_str())
            .ok_or_else(|| anyhow::anyhow!("Invalid filename"))?;
        
        let version_regex = Regex::new(r"^V(\d+)__(.+)$")?;
        let captures = version_regex.captures(filename)
            .ok_or_else(|| anyhow::anyhow!("Invalid migration filename format: {}", filename))?;
        
        let version = captures.get(1).unwrap().as_str().to_string();
        let name = captures.get(2).unwrap().as_str().replace('_', " ");
        
        // è§£æSQLå†…å®¹
        let (up_sql, down_sql) = self.parse_sql_content(&content)?;
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºåŸºçº¿è¿ç§»ï¼ˆç‰ˆæœ¬å·ä¸º000æˆ–SQLå†…å®¹ä¸ºç©ºï¼‰
        let is_baseline = version == "000" || up_sql.trim().is_empty();
        
        // è®¡ç®—æ ¡éªŒå’Œ
        let checksum = self.calculate_checksum(&up_sql);
        
        Ok(MigrationFile {
            version,
            name,
            up_sql,
            down_sql,
            checksum,
            is_baseline,
        })
    }
    
    /// è§£æSQLå†…å®¹ï¼ˆåˆ†ç¦»UPå’ŒDOWNéƒ¨åˆ†ï¼‰
    fn parse_sql_content(&self, content: &str) -> Result<(String, Option<String>)> {
        let lines: Vec<&str> = content.lines().collect();
        let mut up_sql = String::new();
        let mut down_sql: Option<String> = None;
        let mut current_section = Section::Up;
        
        for line in lines {
            let trimmed = line.trim();
            
            if trimmed == "-- +migrate Up" {
                current_section = Section::Up;
                continue;
            } else if trimmed == "-- +migrate Down" {
                current_section = Section::Down;
                down_sql = Some(String::new());
                continue;
            }
            
            // è·³è¿‡æ³¨é‡Šè¡Œï¼ˆä½†ä¿ç•™SQLä¸­çš„æ³¨é‡Šï¼‰
            if trimmed.starts_with("-- ") && !trimmed.contains("/*") {
                continue;
            }
            
            match current_section {
                Section::Up => {
                    up_sql.push_str(line);
                    up_sql.push('\n');
                }
                Section::Down => {
                    if let Some(ref mut down) = down_sql {
                        down.push_str(line);
                        down.push('\n');
                    }
                }
            }
        }
        
        Ok((up_sql.trim().to_string(), down_sql.map(|s| s.trim().to_string())))
    }
    
    /// æ‰§è¡Œå•ä¸ªè¿ç§»
    async fn execute_migration(&self, migration: &MigrationFile) -> Result<MigrationRecord> {
        let start_time = Instant::now();
        
        // å¯¹äºåŸºçº¿è¿ç§»ï¼Œè·³è¿‡SQLæ‰§è¡Œ
        let execution_result = if migration.is_baseline {
            println!("ğŸ“‹ Baseline migration detected, skipping SQL execution");
            Ok(())
        } else {
            // æ‰§è¡ŒSQLè¯­å¥
            self.execute_sql_statements(&migration.up_sql).await
        };
        
        let execution_time = start_time.elapsed();
        let success = execution_result.is_ok();
        let error_message = execution_result.err().map(|e| e.to_string()).unwrap_or_default();
        
        // è®°å½•è¿ç§»ç»“æœ
        let record = MigrationRecord {
            version: migration.version.clone(),
            name: migration.name.clone(),
            applied_at: chrono::Utc::now().format("%Y-%m-%d %H:%M:%S%.3f").to_string(),
            execution_time_ms: execution_time.as_millis() as u64,
            checksum: migration.checksum.clone(),
            success,
            error_message: error_message.clone(),
        };
        
        // ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦è®°å½•ï¼‰
        self.save_migration_record(&record).await?;
        
        // å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œè¿”å›é”™è¯¯
        if !success {
            return Err(anyhow::anyhow!("Migration execution failed: {}", error_message));
        }
        
        Ok(record)
    }
    
    /// æ‰§è¡ŒSQLè¯­å¥ï¼ˆæ”¯æŒå¤šè¯­å¥ï¼‰
    async fn execute_sql_statements(&self, sql: &str) -> Result<()> {
        // å¦‚æœSQLä¸ºç©ºï¼Œç›´æ¥è¿”å›æˆåŠŸ
        if sql.trim().is_empty() {
            println!("ğŸ“ Empty SQL content, skipping execution");
            return Ok(());
        }
        
        // ç®€å•çš„è¯­å¥åˆ†å‰²ï¼ˆæŒ‰åˆ†å·åˆ†å‰²ï¼Œä½†è¦æ³¨æ„å­—ç¬¦ä¸²ä¸­çš„åˆ†å·ï¼‰
        let statements = self.split_sql_statements(sql);
        
        for (i, statement) in statements.iter().enumerate() {
            let trimmed = statement.trim();
            if trimmed.is_empty() {
                continue;
            }
            
            println!("ğŸ” Executing statement {}: {}", i + 1, 
                    &trimmed[..std::cmp::min(100, trimmed.len())]);
            
            self.client.query(trimmed).execute().await
                .with_context(|| format!("Failed to execute statement {}: {}", i + 1, trimmed))?;
        }
        
        Ok(())
    }
    
    /// åˆ†å‰²SQLè¯­å¥
    fn split_sql_statements(&self, sql: &str) -> Vec<String> {
        // ç®€å•å®ç°ï¼šæŒ‰åˆ†å·åˆ†å‰²ï¼Œå¿½ç•¥å­—ç¬¦ä¸²å†…çš„åˆ†å·
        let mut statements = Vec::new();
        let mut current_statement = String::new();
        let mut in_string = false;
        let mut string_delimiter = '\0';
        
        for ch in sql.chars() {
            match ch {
                '\'' | '"' if !in_string => {
                    in_string = true;
                    string_delimiter = ch;
                    current_statement.push(ch);
                }
                ch if in_string && ch == string_delimiter => {
                    in_string = false;
                    current_statement.push(ch);
                }
                ';' if !in_string => {
                    if !current_statement.trim().is_empty() {
                        statements.push(current_statement.trim().to_string());
                        current_statement.clear();
                    }
                }
                _ => {
                    current_statement.push(ch);
                }
            }
        }
        
        // æ·»åŠ æœ€åä¸€ä¸ªè¯­å¥
        if !current_statement.trim().is_empty() {
            statements.push(current_statement.trim().to_string());
        }
        
        statements
    }
    

    

    
    /// ä»æ•°æ®åº“è·å–å·²åº”ç”¨çš„è¿ç§»ç‰ˆæœ¬
    async fn get_applied_versions_from_database(&self) -> Result<HashSet<String>> {
        let mut applied_versions = HashSet::new();
        let table_name = format!("_migrations_{}", self.service_name);
        
        // é¦–å…ˆæ£€æŸ¥è¿ç§»è¡¨æ˜¯å¦å­˜åœ¨
        let table_exists_query = format!("EXISTS TABLE {}", table_name);
        let table_exists = match self.client.query(&table_exists_query).execute().await {
            Ok(_) => true,
            Err(_) => false,
        };
        
        if !table_exists {
            println!("ğŸ“‹ è¿ç§»è¡¨ {} ä¸å­˜åœ¨ï¼Œæ‰€æœ‰è¿ç§»éƒ½æ ‡è®°ä¸ºæœªåº”ç”¨", table_name);
            println!("ğŸ”§ è¿ç§»è¡¨å°†åœ¨é¦–æ¬¡è¿ç§»æ—¶è‡ªåŠ¨åˆ›å»º");
            return Ok(applied_versions);
        }
        
        // ä½¿ç”¨æ›´æ™ºèƒ½çš„æ–¹æ³•ï¼šæŸ¥è¯¢è¿ç§»è¡¨ä¸­å·²åº”ç”¨çš„ç‰ˆæœ¬
        println!("ğŸ“‹ æ£€æµ‹åˆ°è¿ç§»è¡¨å­˜åœ¨ï¼ŒæŸ¥è¯¢å·²åº”ç”¨çš„è¿ç§»ç‰ˆæœ¬");
        applied_versions = self.get_applied_versions_from_table().await?;
        
        println!("ğŸ“‹ æ£€æŸ¥å®Œæˆï¼šå‘ç° {} ä¸ªå·²åº”ç”¨çš„è¿ç§»", applied_versions.len());
        Ok(applied_versions)
    }
    
    /// ä»è¿ç§»è¡¨ä¸­æŸ¥è¯¢å·²åº”ç”¨çš„è¿ç§»ç‰ˆæœ¬
    async fn get_applied_versions_from_table(&self) -> Result<HashSet<String>> {
        let mut applied_versions = HashSet::new();
        let table_name = format!("_migrations_{}", self.service_name);
        
        // ä½¿ç”¨æ–°ç‰ˆæœ¬çš„ ClickHouse å®¢æˆ·ç«¯ç‰¹æ€§æ¥ç²¾ç¡®æŸ¥è¯¢
        println!("ğŸ“‹ ä½¿ç”¨æ–°ç‰ˆæœ¬ ClickHouse å®¢æˆ·ç«¯æŸ¥è¯¢å·²åº”ç”¨çš„è¿ç§»ç‰ˆæœ¬");
        
        // æŸ¥è¯¢è¿ç§»è¡¨ä¸­æ‰€æœ‰å·²åº”ç”¨çš„ç‰ˆæœ¬
        let query = format!("SELECT version FROM {} WHERE success = 1 ORDER BY version", table_name);
        
        // å°è¯•ä½¿ç”¨ fetch_all æ–¹æ³•ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°æ—§æ–¹æ³•
        match self.client.query(&query).fetch_all::<String>().await {
            Ok(rows) => {
                println!("ğŸ“‹ æˆåŠŸæŸ¥è¯¢åˆ° {} ä¸ªå·²åº”ç”¨çš„è¿ç§»", rows.len());
                for version in rows {
                    applied_versions.insert(version.clone());
                    println!("ğŸ“‹ è¿ç§» {} å·²åº”ç”¨", version);
                }
            }
            Err(e) => {
                println!("ğŸ“‹ æŸ¥è¯¢è¿ç§»è¡¨å¤±è´¥: {}", e);
                println!("ğŸ“‹ å›é€€åˆ°æ—§æ–¹æ³•ï¼šå‡è®¾è¿ç§»è¡¨ä¸ºç©ºï¼Œæ‰€æœ‰è¿ç§»æ ‡è®°ä¸ºæœªåº”ç”¨");
            }
        }
        
        Ok(applied_versions)
    }
    

    

    

    

    
    /// ä¿å­˜è¿ç§»è®°å½•
    async fn save_migration_record(&self, record: &MigrationRecord) -> Result<()> {
        let table_name = format!("_migrations_{}", self.service_name);
        
        let insert_sql = format!(
            r#"
            INSERT INTO {table_name} 
            (version, name, applied_at, execution_time_ms, checksum, success, error_message)
            VALUES ('{}', '{}', '{}', {}, '{}', {}, '{}')
            "#,
            record.version,
            record.name.replace('\'', "''"), // è½¬ä¹‰å•å¼•å·
            record.applied_at,
            record.execution_time_ms,
            record.checksum,
            record.success as u8,
            record.error_message.replace('\'', "''")
        );
        
        self.client.query(&insert_sql).execute().await?;
        Ok(())
    }
    
    /// è®¡ç®—SQLå†…å®¹çš„æ ¡éªŒå’Œ
    fn calculate_checksum(&self, content: &str) -> String {
        use sha2::{Sha256, Digest};
        let mut hasher = Sha256::new();
        hasher.update(content.as_bytes());
        format!("{:x}", hasher.finalize())
    }
    
    /// æ˜¯å¦åœ¨å¤±è´¥æ—¶ç»§ç»­æ‰§è¡Œ
    fn should_continue_on_failure(&self) -> bool {
        std::env::var("CONTINUE_ON_MIGRATION_FAILURE")
            .unwrap_or_default() == "true"
    }
    
    /// è·å–è¿ç§»çŠ¶æ€
    pub async fn get_migration_status(&self) -> Result<MigrationStatus> {
        let table_name = format!("_migrations_{}", self.service_name);
        
        // é¦–å…ˆæ£€æŸ¥è¿ç§»è¡¨æ˜¯å¦å­˜åœ¨
        let table_exists_query = format!("EXISTS TABLE {}", table_name);
        let table_exists = match self.client.query(&table_exists_query).execute().await {
            Ok(_) => true,
            Err(_) => false,
        };
        
        let total_migrations = if table_exists {
            // è·å–å·²åº”ç”¨çš„è¿ç§»æ•°é‡
            let count_query = format!("SELECT count() FROM {} WHERE success = 1", table_name);
            match self.client.query(&count_query).execute().await {
                Ok(_) => 1, // ç®€åŒ–å¤„ç†
                Err(_) => 0
            }
        } else {
            0 // è¡¨ä¸å­˜åœ¨ï¼Œè¿ç§»æ•°é‡ä¸º0
        };
        
        let status_message = if table_exists {
            format!("å·²å­˜åœ¨")
        } else {
            format!("ä¸å­˜åœ¨ï¼ˆå°†åœ¨é¦–æ¬¡è¿ç§»æ—¶è‡ªåŠ¨åˆ›å»ºï¼‰")
        };
        
        Ok(MigrationStatus {
            service_name: self.service_name.clone(),
            migrations_table: format!("{} ({})", table_name, status_message),
            total_migrations,
        })
    }
}

#[derive(Debug)]
enum Section {
    Up,
    Down,
}

#[derive(Debug)]
pub struct MigrationStatus {
    pub service_name: String,
    pub migrations_table: String,
    pub total_migrations: usize,
}

impl MigrationSummary {
    fn new() -> Self {
        Self {
            successful: Vec::new(),
            failed: Vec::new(),
            total_time: std::time::Duration::default(),
        }
    }
    
    fn no_migrations() -> Self {
        Self::new()
    }
    
    pub fn is_success(&self) -> bool {
        self.failed.is_empty()
    }
}
