# SQLx é¡¹ç›®é›†æˆå®Œæ•´æŒ‡å—

## ğŸš€ æ¦‚è¿°

SQLx æ˜¯ä¸€ä¸ª Rust å¼‚æ­¥ SQL å·¥å…·åŒ…ï¼Œæ”¯æŒå¤šç§æ•°æ®åº“ï¼ˆPostgreSQLã€MySQLã€SQLiteã€SQL Serverï¼‰ï¼Œæä¾›ç¼–è¯‘æ—¶ SQL æŸ¥è¯¢æ£€æŸ¥ã€ç±»å‹å®‰å…¨å’Œé›¶æˆæœ¬æŠ½è±¡ã€‚

## ğŸ“‹ åœ¨æ–°é¡¹ç›®ä¸­å¼•å…¥ SQLx çš„å®Œæ•´æ­¥éª¤

### 1. é¡¹ç›®åˆå§‹åŒ–

#### 1.1 åˆ›å»ºæ–°é¡¹ç›®
```bash
cargo new my_sqlx_project
cd my_sqlx_project
```

#### 1.2 é…ç½® Cargo.toml
```toml
[package]
name = "my_sqlx_project"
version = "0.1.0"
edition = "2021"

[dependencies]
# å¼‚æ­¥è¿è¡Œæ—¶ - SQLx å¿…éœ€
tokio = { version = "1.0", features = ["full"] }
# SQLx æ ¸å¿ƒ - æ•°æ®åº“è¿æ¥å’Œè¿ç§»å¿…éœ€
sqlx = { version = "0.8", features = [
    "runtime-tokio-rustls",  # å¼‚æ­¥è¿è¡Œæ—¶
    "postgres",              # PostgreSQL æ”¯æŒ
    "chrono",                # æ—¶é—´ç±»å‹æ”¯æŒ
    "uuid",                  # UUID ç±»å‹æ”¯æŒ
    "migrate"                # æ•°æ®åº“è¿ç§»æ”¯æŒ
]}
# ç¯å¢ƒå˜é‡ - ç”¨äºé…ç½®æ•°æ®åº“è¿æ¥
dotenv = "0.15"
```
#### 1.3 å®‰è£… sqlx-cli

cargo install sqlx-cli --features postgres

### 2. ç¯å¢ƒé…ç½®

#### 2.1 åˆ›å»º .env æ–‡ä»¶
```bash
# æ•°æ®åº“è¿æ¥é…ç½®
DATABASE_URL=postgresql://ç”¨æˆ·å:å¯†ç @ä¸»æœº:ç«¯å£/æ•°æ®åº“å

# ç¤ºä¾‹ï¼š
DATABASE_URL=postgresql://sxt:default@localhost:5432/postgres

# æ—¥å¿—çº§åˆ«
RUST_LOG=info

# è¿ç§»å¤±è´¥å¤„ç†ç­–ç•¥
MIGRATION_FAILURE_STRATEGY=manual
```

#### 2.2 æ•°æ®åº“è¿æ¥é…ç½®
```rust
// src/database.rs
use anyhow::{Context, Result};
use sqlx::{PgPool, Row};
use tracing::info;

pub struct DatabaseManager {
    pub pool: PgPool,
}

impl DatabaseManager {
    /// åˆ›å»ºæ•°æ®åº“è¿æ¥æ± 
    pub async fn new_with_config(database_url: &str) -> Result<Self> {
        info!("æ­£åœ¨è¿æ¥æ•°æ®åº“...");
        
        let pool = PgPool::connect_with(
            sqlx::postgres::PgConnectOptions::from_str(database_url)?
                .application_name("my_sqlx_project")
        )
        .await
        .context("æ— æ³•è¿æ¥åˆ°æ•°æ®åº“")?;
        
        // æµ‹è¯•è¿æ¥
        let _row = sqlx::query("SELECT 1")
            .fetch_one(&pool)
            .await
            .context("æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥")?;
        
        info!("æ•°æ®åº“è¿æ¥æˆåŠŸ");
        Ok(Self { pool })
    }
}

/// ä¾¿æ·è¿æ¥å‡½æ•°
pub async fn connect() -> Result<DatabaseManager> {
    dotenv::dotenv().ok();
    
    let database_url = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "postgresql://sxt:default@localhost:5432/postgres".to_string());
    
    DatabaseManager::new_with_config(&database_url).await
}
```

### 3. æ•°æ®åº“è¿ç§»ç³»ç»Ÿ

#### 3.1 ä½¿ç”¨ sqlx-cli ç®¡ç†è¿ç§»
```bash
# åˆ›å»ºæ–°çš„è¿ç§»æ–‡ä»¶
sqlx migrate add create_users_table
# è‹¥å·²æœ‰è¿ç§»æ–‡ä»¶ 001_initial_schema.sqlï¼Œæ–°åˆ›å»ºçš„æ–‡ä»¶åæ ¼å¼ä¼šè·Ÿéšå·²æœ‰æ–‡ä»¶ 002_create_users_table.sql
# è‹¥æ²¡æœ‰ï¼Œä¼šé‡‡ç”¨é»˜è®¤å‘½åæ–¹å¼ 20250903090034_create_users_table.sql

# è¿è¡Œæ‰€æœ‰å¾…å¤„ç†çš„è¿ç§»
sqlx migrate run

# å›æ»šæœ€åä¸€ä¸ªè¿ç§»ï¼ˆä¸€èˆ¬ä¸ç”¨ï¼Œæ‰§è¡Œæ–°çš„è¿ç§»è¦†ç›–ä¹‹å‰çš„è¿ç§»ï¼‰
sqlx migrate revert

# æŸ¥çœ‹è¿ç§»çŠ¶æ€
sqlx migrate info

# åˆ›å»ºè¿ç§»ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
mkdir migrations
```
sqlx migrate run æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å‘½ä»¤è¡Œå·¥å…·æ“ä½œï¼Œå®ƒï¼š
ç›´æ¥è¯»å–è¿ç§»æ–‡ä»¶ - ä» migrations/ ç›®å½•è¯»å– .sql æ–‡ä»¶
ç›´æ¥è¿æ¥æ•°æ®åº“ - ä½¿ç”¨ DATABASE_URL ç¯å¢ƒå˜é‡è¿æ¥æ•°æ®åº“
æ‰§è¡ŒSQLè¯­å¥ - ç›´æ¥åœ¨æ•°æ®åº“ä¸­æ‰§è¡Œè¿ç§»SQL
æ›´æ–°è¿ç§»è¡¨ - åœ¨ _sqlx_migrations è¡¨ä¸­è®°å½•æ‰§è¡ŒçŠ¶æ€
è¿™ä¸ªè¿‡ç¨‹å®Œå…¨ç‹¬ç«‹äºRustä»£ç ç¼–è¯‘ã€‚

è¿è¡Œcargo runä¹Ÿä¼šæ‰§è¡Œè¿ç§»ï¼ˆåœ¨main.rsä¸­ä½¿ç”¨äº†sqlx::migrate!()å®ï¼‰ï¼Œä½†æ˜¯éœ€è¦é‡æ–°ç¼–è¯‘ï¼Œè¿ç§»æ‰ä¼šæˆåŠŸã€‚å› ä¸ºï¼š
å®åœ¨ç¼–è¯‘æ—¶è¯»å–è¿ç§»æ–‡ä»¶
è¿ç§»æ–‡ä»¶çš„å†…å®¹ä¼šè¢«ç¼–è¯‘åˆ°äºŒè¿›åˆ¶æ–‡ä»¶ä¸­
æ–°çš„è¿ç§»æ–‡ä»¶éœ€è¦é‡æ–°ç¼–è¯‘æ‰èƒ½è¢«åŒ…å«

#### 3.2 è¿ç§»æ–‡ä»¶å‘½åè§„åˆ™
```
<ç‰ˆæœ¬å·>_<æè¿°>.sql

ç¤ºä¾‹ï¼š
migrations/
â”œâ”€â”€ 001_initial_schema.sql           # version=1, description="initial schema"
â”œâ”€â”€ 002_add_user_preferences.sql     # version=2, description="add user preferences"
â”œâ”€â”€ 003_create_products_table.sql    # version=3, description="create products table"
â””â”€â”€ 20231201_add_orders_table.sql    # version=20231201, description="add orders table"
```

#### 3.3 è¿ç§»æ–‡ä»¶ç¤ºä¾‹
```sql
-- 001_initial_schema.sql
-- ç”¨æˆ·è¡¨
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(100),
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    is_active BOOLEAN DEFAULT TRUE
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_users_username ON users(username);
```

#### 3.4 è¿ç§»æ‰§è¡Œä»£ç 
```rust
// src/database.rs
impl DatabaseManager {
    /// æ‰§è¡Œæ•°æ®åº“è¿ç§»
    pub async fn safe_migrate(&self) -> Result<()> {
        info!("å¼€å§‹æ‰§è¡Œæ•°æ®åº“è¿ç§»...");
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºç°æœ‰æ•°æ®åº“
        if self.is_existing_database().await? {
            info!("æ£€æµ‹åˆ°ç°æœ‰æ•°æ®åº“ï¼Œå»ºç«‹è¿ç§»åŸºçº¿...");
            self.setup_baseline_for_existing_db().await?;
        }
        
        // æ‰§è¡Œè¿ç§»
        match sqlx::migrate!("./migrations").run(&self.pool).await {
            Ok(_) => {
                info!("âœ… æ•°æ®åº“è¿ç§»å®Œæˆ");
                self.print_migration_status().await?;
                Ok(())
            }
            Err(e) => {
                error!("âŒ è¿ç§»å¤±è´¥: {}", e);
                self.handle_migration_failure().await?;
                Err(anyhow::anyhow!("æ•°æ®åº“è¿ç§»å¤±è´¥: {}", e))
            }
        }
    }
    
    /// æ£€æŸ¥æ˜¯å¦ä¸ºç°æœ‰æ•°æ®åº“
    async fn is_existing_database(&self) -> Result<bool> {
        let table_count: i64 = sqlx::query_scalar(
            "SELECT COUNT(*) FROM information_schema.tables 
             WHERE table_schema = 'public' AND table_type = 'BASE TABLE'"
        )
        .fetch_one(&self.pool)
        .await?;
        
        Ok(table_count > 0)
    }
}
```

#### è¿ç§»è¡¨ _sqlx_migrations
```
CREATE TABLE _sqlx_migrations ( 
    version BIGINT PRIMARY KEY,        -- ä»æ–‡ä»¶åè§£æçš„ç‰ˆæœ¬å·
    description TEXT NOT NULL,         -- ä»æ–‡ä»¶åè§£æçš„æè¿°
    installed_on TIMESTAMPTZ NOT NULL DEFAULT NOW(), -- å®‰è£…æ—¶é—´
    success BOOLEAN NOT NULL,          -- æ‰§è¡Œæ˜¯å¦æˆåŠŸ
    checksum BYTEA NOT NULL,          -- æ–‡ä»¶å†…å®¹æ ¡éªŒå’Œ
    execution_time BIGINT NOT NULL    -- æ‰§è¡Œè€—æ—¶ï¼ˆçº³ç§’ï¼‰
);
```
### 4. æ•°æ®æ¨¡å‹å’ŒæŸ¥è¯¢

#### 4.1 å®šä¹‰æ•°æ®æ¨¡å‹
```rust
// src/models.rs
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};
use rust_decimal::Decimal;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct User {
    pub id: i32,
    pub username: String,
    pub email: String,
    pub password_hash: String,
    pub full_name: Option<String>,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub is_active: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Product {
    pub id: i32,
    pub name: String,
    pub description: Option<String>,
    pub price: Decimal,
    pub category_id: Option<i32>,
    pub stock_quantity: i32,
    pub sku: Option<String>,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub is_active: bool,
}
```

#### 4.2 åŸºç¡€æŸ¥è¯¢æ“ä½œ
```rust
// src/data.rs
use anyhow::{Context, Result};
use sqlx::{PgPool, Row};
use tracing::info;

/// æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·
pub async fn get_all_users(pool: &PgPool) -> Result<Vec<User>> {
    let rows = sqlx::query(
        "SELECT id, username, email, password_hash, full_name, 
                created_at, updated_at, is_active 
         FROM users 
         WHERE is_active = true 
         ORDER BY created_at DESC"
    )
    .fetch_all(pool)
    .await
    .context("æŸ¥è¯¢ç”¨æˆ·å¤±è´¥")?;
    
    let users = rows.into_iter().map(|row| User {
        id: row.get("id"),
        username: row.get("username"),
        email: row.get("email"),
        password_hash: row.get("password_hash"),
        full_name: row.get("full_name"),
        created_at: row.get("created_at"),
        updated_at: row.get("updated_at"),
        is_active: row.get("is_active"),
    }).collect();
    
    Ok(users)
}

/// æ ¹æ®IDæŸ¥è¯¢ç”¨æˆ·
pub async fn get_user_by_id(pool: &PgPool, user_id: i32) -> Result<Option<User>> {
    let row = sqlx::query(
        "SELECT id, username, email, password_hash, full_name, 
                created_at, updated_at, is_active 
         FROM users 
         WHERE id = $1 AND is_active = true"
    )
    .bind(user_id)
    .fetch_optional(pool)
    .await
    .context("æŸ¥è¯¢ç”¨æˆ·å¤±è´¥")?;
    
    match row {
        Some(row) => Ok(Some(User {
            id: row.get("id"),
            username: row.get("username"),
            email: row.get("email"),
            password_hash: row.get("password_hash"),
            full_name: row.get("full_name"),
            created_at: row.get("created_at"),
            updated_at: row.get("updated_at"),
            is_active: row.get("is_active"),
        })),
        None => Ok(None),
    }
}

/// åˆ›å»ºæ–°ç”¨æˆ·
pub async fn create_user(
    pool: &PgPool, 
    username: &str, 
    email: &str, 
    password_hash: &str, 
    full_name: Option<&str>
) -> Result<User> {
    let row = sqlx::query(
        "INSERT INTO users (username, email, password_hash, full_name) 
         VALUES ($1, $2, $3, $4) 
         RETURNING id, username, email, password_hash, full_name, 
                   created_at, updated_at, is_active"
    )
    .bind(username)
    .bind(email)
    .bind(password_hash)
    .bind(full_name)
    .fetch_one(pool)
    .await
    .context("åˆ›å»ºç”¨æˆ·å¤±è´¥")?;
    
    Ok(User {
        id: row.get("id"),
        username: row.get("username"),
        email: row.get("email"),
        password_hash: row.get("password_hash"),
        full_name: row.get("full_name"),
        created_at: row.get("created_at"),
        updated_at: row.get("updated_at"),
        is_active: row.get("is_active"),
    })
}

/// æ›´æ–°ç”¨æˆ·ä¿¡æ¯
pub async fn update_user(
    pool: &PgPool, 
    user_id: i32, 
    updates: &UserUpdate
) -> Result<Option<User>> {
    let mut query_parts = Vec::new();
    let mut bind_values = Vec::new();
    let mut param_count = 1;
    
    if let Some(username) = &updates.username {
        query_parts.push(format!("username = ${}", param_count));
        bind_values.push(username);
        param_count += 1;
    }
    
    if let Some(email) = &updates.email {
        query_parts.push(format!("email = ${}", param_count));
        bind_values.push(email);
        param_count += 1;
    }
    
    if let Some(full_name) = &updates.full_name {
        query_parts.push(format!("full_name = ${}", param_count));
        bind_values.push(full_name);
        param_count += 1;
    }
    
    if query_parts.is_empty() {
        return Ok(None);
    }
    
    query_parts.push("updated_at = CURRENT_TIMESTAMP".to_string());
    
    let query = format!(
        "UPDATE users SET {} WHERE id = ${} AND is_active = true 
         RETURNING id, username, email, password_hash, full_name, 
                   created_at, updated_at, is_active",
        query_parts.join(", "), param_count
    );
    
    let mut query_builder = sqlx::query(&query);
    for value in bind_values {
        query_builder = query_builder.bind(value);
    }
    query_builder = query_builder.bind(user_id);
    
    let row = query_builder
        .fetch_optional(pool)
        .await
        .context("æ›´æ–°ç”¨æˆ·å¤±è´¥")?;
    
    match row {
        Some(row) => Ok(Some(User {
            id: row.get("id"),
            username: row.get("username"),
            email: row.get("email"),
            password_hash: row.get("password_hash"),
            full_name: row.get("full_name"),
            created_at: row.get("created_at"),
            updated_at: row.get("updated_at"),
            is_active: row.get("is_active"),
        })),
        None => Ok(None),
    }
}

/// åˆ é™¤ç”¨æˆ·ï¼ˆè½¯åˆ é™¤ï¼‰
pub async fn delete_user(pool: &PgPool, user_id: i32) -> Result<bool> {
    let result = sqlx::query(
        "UPDATE users SET is_active = false, updated_at = CURRENT_TIMESTAMP 
         WHERE id = $1 AND is_active = true"
    )
    .bind(user_id)
    .execute(pool)
    .await
    .context("åˆ é™¤ç”¨æˆ·å¤±è´¥")?;
    
    Ok(result.rows_affected() > 0)
}
```

#### 4.3 å¤æ‚æŸ¥è¯¢ç¤ºä¾‹
```rust
/// åˆ†é¡µæŸ¥è¯¢ç”¨æˆ·
pub async fn get_users_paginated(
    pool: &PgPool, 
    page: i64, 
    page_size: i64,
    search: Option<&str>
) -> Result<(Vec<User>, i64)> {
    let offset = (page - 1) * page_size;
    
    // æ„å»ºæœç´¢æ¡ä»¶
    let search_condition = if let Some(search_term) = search {
        "WHERE (username ILIKE $1 OR email ILIKE $1 OR full_name ILIKE $1) AND is_active = true"
    } else {
        "WHERE is_active = true"
    };
    
    // æŸ¥è¯¢æ€»æ•°
    let count_query = if search.is_some() {
        "SELECT COUNT(*) FROM users WHERE (username ILIKE $1 OR email ILIKE $1 OR full_name ILIKE $1) AND is_active = true"
    } else {
        "SELECT COUNT(*) FROM users WHERE is_active = true"
    };
    
    let total_count: i64 = if let Some(search_term) = search {
        sqlx::query_scalar(count_query)
            .bind(format!("%{}%", search_term))
            .fetch_one(pool)
            .await?
    } else {
        sqlx::query_scalar(count_query)
            .fetch_one(pool)
            .await?
    };
    
    // æŸ¥è¯¢æ•°æ®
    let data_query = format!(
        "SELECT id, username, email, password_hash, full_name, 
                created_at, updated_at, is_active 
         FROM users 
         {} 
         ORDER BY created_at DESC 
         LIMIT $1 OFFSET $2",
        search_condition
    );
    
    let rows = if let Some(search_term) = search {
        sqlx::query(&data_query)
            .bind(format!("%{}%", search_term))
            .bind(page_size)
            .bind(offset)
            .fetch_all(pool)
            .await?
    } else {
        sqlx::query(&data_query)
            .bind(page_size)
            .bind(offset)
            .fetch_all(pool)
            .await?
    };
    
    let users = rows.into_iter().map(|row| User {
        id: row.get("id"),
        username: row.get("username"),
        email: row.get("email"),
        password_hash: row.get("password_hash"),
        full_name: row.get("full_name"),
        created_at: row.get("created_at"),
        updated_at: row.get("updated_at"),
        is_active: row.get("is_active"),
    }).collect();
    
    Ok((users, total_count))
}

/// ç»Ÿè®¡æŸ¥è¯¢
pub async fn get_user_statistics(pool: &PgPool) -> Result<UserStatistics> {
    let stats = sqlx::query(
        "SELECT 
            COUNT(*) as total_users,
            COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '30 days' THEN 1 END) as new_users_30d,
            COUNT(CASE WHEN created_at >= CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as new_users_7d,
            COUNT(CASE WHEN created_at >= CURRENT_DATE THEN 1 END) as new_users_today
         FROM users 
         WHERE is_active = true"
    )
    .fetch_one(pool)
    .await
    .context("è·å–ç”¨æˆ·ç»Ÿè®¡å¤±è´¥")?;
    
    Ok(UserStatistics {
        total_users: stats.get("total_users"),
        new_users_30d: stats.get("new_users_30d"),
        new_users_7d: stats.get("new_users_7d"),
        new_users_today: stats.get("new_users_today"),
    })
}
```

### 5. ä¸»ç¨‹åºé›†æˆ

#### 5.1 ä¸»ç¨‹åºç¤ºä¾‹
```rust
// src/main.rs
mod database;
mod models;
mod data;

use anyhow::Result;
use tracing::{info, error};

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt::init();
    
    info!("ğŸš€ å¯åŠ¨ SQLx é¡¹ç›®");
    
    // åŠ è½½ç¯å¢ƒå˜é‡
    dotenv::dotenv().ok();
    
    // è¿æ¥æ•°æ®åº“
    let db_manager = match database::connect().await {
        Ok(manager) => {
            info!("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ");
            manager
        }
        Err(e) => {
            error!("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {}", e);
            return Err(e);
        }
    };
    
    // æ‰§è¡Œæ•°æ®åº“è¿ç§»
    info!("ğŸ“‹ å¼€å§‹æ‰§è¡Œæ•°æ®åº“è¿ç§»...");
    match db_manager.safe_migrate().await {
        Ok(_) => {
            info!("âœ… æ•°æ®åº“è¿ç§»å®Œæˆ");
        }
        Err(e) => {
            error!("âŒ æ•°æ®åº“è¿ç§»å¤±è´¥: {}", e);
            return Err(e);
        }
    }
    
    // ç¤ºä¾‹ï¼šåˆ›å»ºç”¨æˆ·
    info!("ğŸ‘¤ åˆ›å»ºç¤ºä¾‹ç”¨æˆ·...");
    match data::create_user(
        &db_manager.pool,
        "testuser",
        "test@example.com",
        "hashed_password",
        Some("æµ‹è¯•ç”¨æˆ·")
    ).await {
        Ok(user) => {
            info!("âœ… ç”¨æˆ·åˆ›å»ºæˆåŠŸ: {}", user.username);
        }
        Err(e) => {
            error!("âŒ ç”¨æˆ·åˆ›å»ºå¤±è´¥: {}", e);
        }
    }
    
    // ç¤ºä¾‹ï¼šæŸ¥è¯¢ç”¨æˆ·
    info!("ğŸ” æŸ¥è¯¢ç”¨æˆ·åˆ—è¡¨...");
    match data::get_all_users(&db_manager.pool).await {
        Ok(users) => {
            info!("âœ… æŸ¥è¯¢åˆ° {} ä¸ªç”¨æˆ·", users.len());
            for user in users {
                info!("  - {} ({})", user.username, user.email);
            }
        }
        Err(e) => {
            error!("âŒ æŸ¥è¯¢ç”¨æˆ·å¤±è´¥: {}", e);
        }
    }
    
    // ç¤ºä¾‹ï¼šåˆ†é¡µæŸ¥è¯¢
    info!("ğŸ“„ åˆ†é¡µæŸ¥è¯¢ç”¨æˆ·...");
    match data::get_users_paginated(&db_manager.pool, 1, 10, None).await {
        Ok((users, total)) => {
            info!("âœ… åˆ†é¡µæŸ¥è¯¢æˆåŠŸ: ç¬¬1é¡µï¼Œå…±{}ä¸ªç”¨æˆ·ï¼Œæ€»æ•°{}", users.len(), total);
        }
        Err(e) => {
            error!("âŒ åˆ†é¡µæŸ¥è¯¢å¤±è´¥: {}", e);
        }
    }
    
    info!("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ");
    
    // å…³é—­æ•°æ®åº“è¿æ¥
    db_manager.close().await;
    
    Ok(())
}
```

### 6. é«˜çº§ç‰¹æ€§

#### 6.1 äº‹åŠ¡å¤„ç†
```rust
/// ä½¿ç”¨äº‹åŠ¡åˆ›å»ºç”¨æˆ·å’Œè®¢å•
pub async fn create_user_with_order(
    pool: &PgPool,
    user_data: &UserCreate,
    order_data: &OrderCreate
) -> Result<(User, Order)> {
    let mut tx = pool.begin().await?;
    
    // åœ¨äº‹åŠ¡ä¸­åˆ›å»ºç”¨æˆ·
    let user = create_user_in_transaction(&mut tx, user_data).await?;
    
    // åœ¨äº‹åŠ¡ä¸­åˆ›å»ºè®¢å•
    let order = create_order_in_transaction(&mut tx, &user.id, order_data).await?;
    
    // æäº¤äº‹åŠ¡
    tx.commit().await?;
    
    Ok((user, order))
}

async fn create_user_in_transaction(
    tx: &mut sqlx::Transaction<'_, sqlx::Postgres>,
    user_data: &UserCreate
) -> Result<User> {
    let row = sqlx::query(
        "INSERT INTO users (username, email, password_hash, full_name) 
         VALUES ($1, $2, $3, $4) 
         RETURNING id, username, email, password_hash, full_name, 
                   created_at, updated_at, is_active"
    )
    .bind(&user_data.username)
    .bind(&user_data.email)
    .bind(&user_data.password_hash)
    .bind(&user_data.full_name)
    .fetch_one(&mut **tx)
    .await?;
    
    Ok(User {
        id: row.get("id"),
        username: row.get("username"),
        email: row.get("email"),
        password_hash: row.get("password_hash"),
        full_name: row.get("full_name"),
        created_at: row.get("created_at"),
        updated_at: row.get("updated_at"),
        is_active: row.get("is_active"),
    })
}
```

#### 6.2 è¿æ¥æ± é…ç½®
```rust
use sqlx::postgres::PgPoolOptions;

pub async fn create_connection_pool(database_url: &str) -> Result<PgPool> {
    let pool = PgPoolOptions::new()
        .max_connections(20)           // æœ€å¤§è¿æ¥æ•°
        .min_connections(5)            // æœ€å°è¿æ¥æ•°
        .acquire_timeout(Duration::from_secs(30))  // è·å–è¿æ¥è¶…æ—¶
        .idle_timeout(Duration::from_secs(600))    // ç©ºé—²è¿æ¥è¶…æ—¶
        .max_lifetime(Duration::from_secs(1800))   // è¿æ¥æœ€å¤§ç”Ÿå‘½å‘¨æœŸ
        .connect(database_url)
        .await?;
    
    Ok(pool)
}
```

### 7. æµ‹è¯•å’ŒéªŒè¯

#### 7.1 è¿è¡Œé¡¹ç›®
```bash
# ç¼–è¯‘
cargo build

# è¿è¡Œ
cargo run

# æˆ–è€…ä½¿ç”¨è„šæœ¬
./run.sh
```

#### 7.2 éªŒè¯æ•°æ®åº“
```bash
# ä½¿ç”¨ sqlx-cli éªŒè¯æ•°æ®åº“
sqlx migrate info

# è¿æ¥åˆ°æ•°æ®åº“
psql postgresql://ç”¨æˆ·å:å¯†ç @ä¸»æœº:ç«¯å£/æ•°æ®åº“å

# æŸ¥çœ‹è¿ç§»è¡¨
SELECT * FROM _sqlx_migrations ORDER BY version;

# æŸ¥çœ‹åˆ›å»ºçš„è¡¨
\dt

# æŸ¥çœ‹è¡¨ç»“æ„
\d users
```

## ğŸ¯ å…³é”®ä¼˜åŠ¿

1. **ç¼–è¯‘æ—¶ SQL æ£€æŸ¥** - åœ¨ç¼–è¯‘æ—¶éªŒè¯ SQL è¯­æ³•
2. **ç±»å‹å®‰å…¨** - ç¼–è¯‘æ—¶ç±»å‹æ£€æŸ¥ï¼Œé¿å…è¿è¡Œæ—¶é”™è¯¯
3. **å¼‚æ­¥æ”¯æŒ** - åŸºäº Tokio çš„é«˜æ€§èƒ½å¼‚æ­¥æ“ä½œ
4. **è¿ç§»ç®¡ç†** - å†…ç½®æ•°æ®åº“ç‰ˆæœ¬æ§åˆ¶
5. **è¿æ¥æ± ** - é«˜æ•ˆçš„æ•°æ®åº“è¿æ¥ç®¡ç†
6. **äº‹åŠ¡æ”¯æŒ** - å®Œæ•´çš„äº‹åŠ¡å¤„ç†èƒ½åŠ›
7. **å¤šæ•°æ®åº“æ”¯æŒ** - PostgreSQLã€MySQLã€SQLiteã€SQL Server

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **è¿ç§»æ–‡ä»¶å‘½å** - å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç‰ˆæœ¬å·_æè¿°.sql æ ¼å¼
2. **ç¯å¢ƒå˜é‡** - ç¡®ä¿ DATABASE_URL æ­£ç¡®é…ç½®
3. **ä¾èµ–ç‰¹æ€§** - æ ¹æ®æ•°æ®åº“ç±»å‹é€‰æ‹©æ­£ç¡®çš„ features
4. **é”™è¯¯å¤„ç†** - ä½¿ç”¨ anyhow æˆ– thiserror è¿›è¡Œé”™è¯¯å¤„ç†
5. **æ—¥å¿—è®°å½•** - ä½¿ç”¨ tracing è¿›è¡Œç»“æ„åŒ–æ—¥å¿—è®°å½•

## ğŸ› ï¸ sqlx-cli å¼€å‘å·¥å…·ä½¿ç”¨æŒ‡å—

### å®‰è£…å’Œé…ç½®
```bash
# å®‰è£… sqlx-cli
cargo install sqlx-cli --no-default-features --features postgres

# éªŒè¯å®‰è£…
sqlx --version

# æŸ¥çœ‹å¸®åŠ©
sqlx --help
```

### æ•°æ®åº“ç®¡ç†
```bash
# åˆ›å»ºæ•°æ®åº“
sqlx database create

# åˆ é™¤æ•°æ®åº“ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
sqlx database drop

# é‡ç½®æ•°æ®åº“ï¼ˆåˆ é™¤æ‰€æœ‰è¡¨å’Œæ•°æ®ï¼‰
sqlx database reset

# è®¾ç½®æ•°æ®åº“ URL
export DATABASE_URL="postgresql://ç”¨æˆ·å:å¯†ç @ä¸»æœº:ç«¯å£/æ•°æ®åº“å"
```

### è¿ç§»ç®¡ç†
```bash
# åˆ›å»ºæ–°è¿ç§»
sqlx migrate add <è¿ç§»åç§°>

# ç¤ºä¾‹ï¼š
sqlx migrate add create_users_table
sqlx migrate add add_user_email_index
sqlx migrate add modify_user_status

# è¿è¡Œè¿ç§»
sqlx migrate run

# å›æ»šè¿ç§»
sqlx migrate revert

# æŸ¥çœ‹è¿ç§»çŠ¶æ€
sqlx migrate info

# æŸ¥çœ‹è¿ç§»å†å²
sqlx migrate list
```

### å¼€å‘è¾…åŠ©åŠŸèƒ½
```bash
# éªŒè¯ SQL æŸ¥è¯¢ï¼ˆç¼–è¯‘æ—¶æ£€æŸ¥ï¼‰
sqlx prepare

# ç”ŸæˆæŸ¥è¯¢æ£€æŸ¥æ–‡ä»¶
sqlx prepare --check

# ç¦»çº¿æ¨¡å¼è¿è¡Œï¼ˆä¸éœ€è¦æ•°æ®åº“è¿æ¥ï¼‰
sqlx migrate run --offline

# æŸ¥çœ‹æ•°æ®åº“è¿æ¥çŠ¶æ€
sqlx migrate info --connect-timeout 5
```

### å¸¸ç”¨å·¥ä½œæµç¨‹
```bash
# 1. å¼€å‘æ–°åŠŸèƒ½æ—¶
sqlx migrate add add_new_feature
# ç¼–è¾‘ç”Ÿæˆçš„ .sql æ–‡ä»¶
sqlx migrate run

# 2. æµ‹è¯•è¿ç§»
sqlx migrate run --offline  # æ£€æŸ¥è¯­æ³•
sqlx migrate run            # å®é™…æ‰§è¡Œ

# 3. å›æ»šæµ‹è¯•
sqlx migrate revert         # å›æ»šæœ€åä¸€ä¸ªè¿ç§»
sqlx migrate run            # é‡æ–°åº”ç”¨

# 4. é‡ç½®å¼€å‘ç¯å¢ƒ
sqlx database reset         # æ¸…ç©ºæ•°æ®åº“
sqlx migrate run            # é‡æ–°åº”ç”¨æ‰€æœ‰è¿ç§»
```

### ç¯å¢ƒå˜é‡é…ç½®
```bash
# åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®
DATABASE_URL=postgresql://ç”¨æˆ·å:å¯†ç @ä¸»æœº:ç«¯å£/æ•°æ®åº“å
SQLX_OFFLINE=false          # æ˜¯å¦å¯ç”¨ç¦»çº¿æ¨¡å¼
SQLX_LOG=debug             # æ—¥å¿—çº§åˆ«
```

## ğŸ“š å‚è€ƒèµ„æº

- [SQLx å®˜æ–¹æ–‡æ¡£](https://docs.rs/sqlx)
- [SQLx GitHub ä»“åº“](https://github.com/launchbadge/sqlx)
- [SQLx CLI æ–‡æ¡£](https://github.com/launchbadge/sqlx/tree/main/sqlx-cli)
- [PostgreSQL å®˜æ–¹æ–‡æ¡£](https://www.postgresql.org/docs/)
- [Rust å¼‚æ­¥ç¼–ç¨‹æŒ‡å—](https://rust-lang.github.io/async-book/)

